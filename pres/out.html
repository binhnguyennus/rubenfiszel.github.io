<!DOCTYPE html>
<html>
    <head>
	<meta charset="utf-8">
	<meta name="generator" content="pandoc">
		<meta name="author" content="Ruben Fiszel">
				<title>Accelerated Sensor Fusion for drones and a simulation framework for Spatial</title>
	<meta name="apple-mobile-web-app-capable" content="yes">
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
	<link rel="stylesheet" href="reveal.js/css/reveal.css">
	<style type="text/css">code{white-space: pre;}</style>
				<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
			<link rel="stylesheet" href="mermaid.css"/>
		<!-- Printing and PDF exports -->
	<script>
	 var link = document.createElement( 'link' );
	 link.rel = 'stylesheet';
	 link.type = 'text/css';
	 link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
	 document.getElementsByTagName( 'head' )[0].appendChild( link );
	</script>
	<!--[if lt IE 9]>
	    <script src="reveal.js/lib/js/html5shiv.js"></script>
	<![endif]-->
		    </head>
    <body>
		<div class="reveal">
	    <div class="slides">

				<section>
		    <h1 class="title">Accelerated Sensor Fusion for drones and a simulation framework for Spatial</h1>
		    		    		    <p class="author">Ruben Fiszel</p>
		    		    		    <p class="date">Feb-Aug 2017</p>
		    		</section>
				
		<section id="outline" class="slide level2">
<h2>Outline</h2>
<ol type="1">
<li><strong>Rao-Blackwellized Particle Filter</strong> for <strong>POSE</strong></li>
<li><strong>Scala-flow</strong></li>
<li>An <strong>interpreter</strong> for Spatial</li>
<li><strong>Spatial implementation</strong> of the RBPF.</li>
</ol>
<aside class="notes">
<ol type="1">
<li>Adapted a novel more accurate algorithm to the context of POSE estimation of drones: <strong>Rao-Blackwellized Particle Filter</strong></li>
<li>Built a <strong>simulation framework</strong>: <strong>scala-flow</strong></li>
<li>Created an <strong>interpreter</strong> for scala-flow integration of spatial</li>
<li><strong>Implemented</strong> the RBPF in hardware with <strong>Spatial</strong></li>
</ol>
</aside>
</section>
<section><section id="introduction" class="titleslide slide level1"><h1>Introduction</h1></section><section id="decline-of-moores-law" class="slide level2">
<h2>Decline of Moore‚Äôs law</h2>
<figure>
<img src="images/moorelaw.png" alt="log-scale growth of the number of transistors" style="width:70.0%" /><figcaption>log-scale growth of the number of transistors</figcaption>
</figure>
</section><section id="rise-of-hardwares-importance" class="slide level2">
<h2>Rise of hardware‚Äôs importance</h2>
<p>FPGA key advantages:</p>
<ul>
<li><strong>Perf/Watt</strong></li>
<li>high throughput</li>
<li>low latency</li>
</ul>
</section><section id="industry-is-moving-to-hardware" class="slide level2">
<h2>Industry is moving to hardware</h2>
<p>Any HPC task can benefit from hardware:</p>
<ul>
<li><strong>Financial industry</strong> (High-Frequency Trading) relies on FPGA</li>
<li><strong>Microsoft</strong> and <strong>Baidu</strong> use FPGA inside their data centers</li>
<li><strong>Google</strong> uses TPU to accelerate deep learning in the cloud</li>
</ul>
</section><section id="spatial-to-ease-transition" class="slide level2">
<h2>Spatial to ease transition</h2>
<ul>
<li>Writing hardware is <strong>hard</strong>: An application has to be written in an <strong>HDL</strong></li>
<li><strong>Spatial</strong> is a high-level <strong>HDL</strong>, implemented as a <strong>DSL</strong> embedded in <strong>Scala</strong></li>
<li>The abstraction level bridges the gap between software and electrical engineers</li>
</ul>
</section></section>
<section><section id="rao-blackwellized-particle-filter-for-pose-estimation" class="titleslide slide level1"><h1>Rao-Blackwellized Particle Filter for POSE estimation</h1></section><section id="motivation" class="slide level2">
<h2>Motivation</h2>
<iframe width="560" height="315" src="https://www.youtube.com/embed/kdlhfMiWVV0" frameborder="0" allowfullscreen>
</iframe>
</section><section id="drones" class="slide level2">
<h2>Drones</h2>
<figure>
<img src="images/f450.jpg" alt="F450" /><figcaption>F450</figcaption>
</figure>
</section><section id="pose-estimation" class="slide level2">
<h2>POSE estimation</h2>
<p>Tracking through time:</p>
<ul>
<li><strong>position</strong></li>
<li><strong>orientation</strong> (called attitude)</li>
</ul>
<p>from</p>
<ul>
<li>linear acceleration (<strong>accelerometer</strong>)</li>
<li>angular velocity (<strong>gyroscope</strong>)</li>
<li>position and orientation (<strong>VICON</strong>)</li>
</ul>
</section><section id="sensor-fusion" class="slide level2">
<h2>Sensor fusion</h2>
<p>The VICON has a <strong>low</strong> sampling rate, so we want use the inertial measurements <strong>in-between</strong>.</p>
<p>Each sensor has a noise that we can reduce by combining the different inputs</p>
</section><section id="problem" class="slide level2">
<h2>Problem</h2>
<ul>
<li>The orientation does not belong to a <strong>vector space</strong> but to <span class="math inline"><em>S</em><em>O</em>(3)</span></li>
<li>Orientations are reprensented with <strong>quaternions</strong>: 4D complex numbers</li>
<li>The transformations through time are non-linear</li>
<li>Mathematically, this is much harder to formalize</li>
</ul>
</section><section id="trajectory-data-generation" class="slide level2">
<h2>Trajectory data generation</h2>
<ul>
<li>Fixed number of randomly generated checkpoints</li>
<li>Checkpoints have Position, Velocity* and Acceleration*</li>
<li>Closed form solutions exist for the ODE constrained on maximal thrust and angular momentum.</li>
</ul>
<p>*: Optional</p>
</section><section id="section" class="slide level2">
<h2></h2>
<video autoplay loop width="70%">
<source src="images/flight.webm" type="video/webm">
</video>
</section><section id="filtering" class="slide level2">
<h2>Filtering</h2>
<p>Given the current and previous observations, calculate the expected current state.</p>
<p><br /><span class="math display">ùîº[<strong>s</strong><sub><em>t</em></sub>|<strong>z</strong><sub>1‚ÄÑ:‚ÄÑ<em>t</em></sub>]</span><br /></p>
</section><section id="bayesian-inference" class="slide level2">
<h2>Bayesian inference</h2>
<p>‚ÄúBayesian inference is a method of statistical inference in which Bayes‚Äô theorem is used to update the probability for a hypothesis as more evidence or information becomes available‚Äù</p>
<p><span class="math inline">‚áí</span></p>
<p>Update the model‚Äôs probability distribution according to new observations</p>
</section><section id="kalman-filter" class="slide level2">
<h2>Kalman Filter</h2>
<p><strong>Assumptions</strong>: The transformation from the model dynamics must be linear</p>
<p>The state (position and orientation) is kept track of as a gaussian distribution.</p>
<p>linear transformation of a gaussian distribution is a new gaussian distribution</p>
<p>next state gaussian from model dynamics is combined with state from observation to compute the new gaussian</p>
</section><section id="section-1" class="slide level2">
<h2></h2>
<figure>
<img src="images/gauss_4.jpg" alt="combined" /><figcaption>combined</figcaption>
</figure>
</section><section id="extended-kalman-filter" class="slide level2">
<h2>Extended Kalman Filter</h2>
<p>To extend the Kalman Filter to non-linear transformations</p>
<p>linearize the transformation with the Jacobian.</p>
</section><section id="unscented-kalman-filter" class="slide level2">
<h2>Unscented Kalman Filter</h2>
<p>The jacobian apply the same linearized transformation to every element of the distribution</p>
<p>But the tail might require a very different transformation</p>
<p>The distribution is here represented with sigma points (representative of the distribution).</p>
<p>The <strong>sigma points</strong> are transformed individually and represent the distribution</p>
</section><section id="section-2" class="slide level2">
<h2></h2>
<figure>
<img src="images/unscented.jpg" alt="Unscented transform" /><figcaption>Unscented transform</figcaption>
</figure>
</section><section id="particle-filter" class="slide level2">
<h2>Particle Filter</h2>
<p>Particle filters also keeps multiple representative of the distribution: Particles instead of sigma points</p>
<p>Each particle has a weight attached to it, which is its importance to represent the distribution. This is <strong>importance sampling</strong></p>
</section><section id="rao-blackwellized-particle-filter" class="slide level2">
<h2>Rao-Blackwellized Particle Filter</h2>
<p>Each particle, instead of representing a state, represent a distribution of the state.</p>
<p>Kalman filtering is used to update the individual states. Best of both world:</p>
<ul>
<li>non-linear components are latent variables updated with the particle filter</li>
<li>linear components are updated with Kalman filtering (and asynchronous with partial Kalman update)</li>
</ul>
</section><section id="section-3" class="slide level2">
<h2></h2>
<p>The most accurate and mathematically sound algorithm</p>
<p>But the most computationally expensive</p>
<p>embarrassingly parallel, hardware is a good fit</p>
</section><section id="result" class="slide level2">
<h2>Result</h2>
<figure>
<img src="images/full-plot.png" alt="Plots" /><figcaption>Plots</figcaption>
</figure>
</section><section id="section-4" class="slide level2">
<h2></h2>
<figure>
<img src="images/barplot.png" alt="Results" /><figcaption>Results</figcaption>
</figure>
</section></section>
<section><section id="scala-flow" class="titleslide slide level1"><h1>Scala-flow</h1></section><section id="data-flow" class="slide level2">
<h2>Data-flow</h2>
<p><a href="https://asciinema.org/a/YCr4mxI2j90T0alUHZzHY56vv"><img src="https://asciinema.org/a/YCr4mxI2j90T0alUHZzHY56vv.png" alt="asciicast" /></a></p>
</section><section id="packet" class="slide level2">
<h2>Packet</h2>
<p>Each packet is typed, contains a timestamp of creation and the total delay it has been through</p>
</section><section id="node" class="slide level2">
<h2>Node</h2>
<p>A node is a processing component of the data-flow. It has an arbitrary number of input and 1 output.</p>
<p>The input and output is typed</p>
</section><section id="block" class="slide level2">
<h2>Block</h2>
<p>A Block is a group of node that can be seen from the outside as a single node</p>
</section><section id="batch" class="slide level2">
<h2>Batch</h2>
<p>A Batch is a node that process internally the elements all at once.</p>
<p>Scheduler ensure correctness of the simulation when different batch are input of the same node.</p>
</section><section id="scheduler" class="slide level2">
<h2>Scheduler</h2>
<div>
<!-- htmlmin:ignore -->
<div class="mermaid">
graph LR
  subgraph scheduler 1
  sA(sourceA)
  end
  subgraph scheduler 2
  sB(sourceB)
  end
  subgraph scheduler 3  
  sC(sourceC)   
  end
  subgraph scheduler 4
  node(Node)
  rest(...)
  end
  sA--&gt;node
  sB--&gt;node
  sC--&gt;node
  node--&gt;rest
</div>
<!-- htmlmin:ignore -->
</div>
</section><section id="section-5" class="slide level2">
<h2></h2>
<div>
<!-- htmlmin:ignore -->
<div class="mermaid">
graph LR
  subgraph scheduler 1
  sA(sourceA)
  end
  subgraph scheduler 2
  sB(sourceB)
  end
  subgraph scheduler 3  
  sC(sourceC)   
  end
  subgraph scheduler 4
  replay1(Replay1)
  replay2(Replay2)
  replay3(Replay3)
  end   
  subgraph scheduler 5
  node(Node)
  rest(...)
  end
  sA--&gt;replay1
  sB--&gt;replay2
  sC--&gt;replay3
  replay1--&gt;node
  replay2--&gt;node
  replay3--&gt;node    
  node--&gt;rest
</div>
<!-- htmlmin:ignore -->
</div>
</section><section id="functionnal-api" class="slide level2">
<h2>Functionnal API</h2>
<pre><code>val sa: Source[A]
val sb: Source[B]
val sla: Source[List[A]]
def f(x: A): C
def b(x: A): Boolean

sa.map(f): Source[C]
sa.zip(sb): Source[(A, B)]
sab.unzip: (Source[A], Source[B])
sa.merge(sb): Source[Either[A, B]]
sa.fusion(sa): Source[A]
sa.foreach(f): Source[A]
sa.filter(b): Source[A]
sa.drop(n): Source[A]
sa.accumulate(clock): Source[List[A]]
sa.groupBy(A =&gt; B): Source[(B, A)]
sla.reduce(r): Source[A]
sa.takeWhile(b): Source[A]
sa.muted: Source[B]
sa.toTime: Source[Time]
sa.latency: Source[A]
sa.debug //print packets as they arrive
//and more ...
composable
sa.zip(sb).map(g).filter(c) ...</code></pre>
</section></section>
<section><section id="interpreter-for-spatial" class="titleslide slide level1"><h1>Interpreter for Spatial</h1></section><section id="section-6" class="slide level2">
<h2></h2>
<p><a href="https://asciinema.org/a/twkwh0Wt2vAjMQFLu6fqGVWK7"><img src="https://asciinema.org/a/twkwh0Wt2vAjMQFLu6fqGVWK7.png" alt="asciicast" /></a></p>
</section><section id="compiler" class="slide level2">
<h2>Compiler</h2>
<p>The compiler runs at scala runtime</p>
<p>It is implemented on top of Argon, a fork of LMS, developped here by Tiark</p>
</section><section id="section-7" class="slide level2">
<h2></h2>
<div>
<!-- htmlmin:ignore -->
<div class="mermaid">
graph LR
  subgraph Scala Compile Time: 1st stage
  prog(Meta-Program)
  scalac
  end
  subgraph Scala Runtime: 2nd stage
  exec(Executable Meta-Program)
  expanded(expanded DSL nodes)
  OIR(raw IR)
  subgraph passes
  transformer
  IR(IR)
  end
  codegen
  target(Chisel Object Program)
  chisel[Chisel Compiler]
  target2(Verilog Program)  
  verilog[Verilog Compiler] 
  target3(Hardware Design)
  end
  prog--&gt;scalac
  scalac--&gt;exec
  exec--&gt;|meta-expansion|expanded
  expanded--&gt;|staging|OIR
  OIR--&gt;transformer
  IR--&gt;transformer
  transformer--&gt;IR
  IR--&gt;codegen
  codegen--&gt;target
  target--&gt;chisel
  chisel--&gt;target2
  target2--&gt;verilog
  verilog--&gt;target3
</div>
<!-- htmlmin:ignore -->
</div>
</section><section id="interpreter" class="slide level2">
<h2>Interpreter</h2>
<div>
<!-- htmlmin:ignore -->
<div class="mermaid">
graph LR
  subgraph Scala Compile Time: 1st stage
  prog(Meta-Program)
  scalac
  end
  subgraph Scala Runtime: 2nd stage
  exec(Executable Meta-Program)
  expanded(expanded DSL nodes)
  OIR(raw IR)
  subgraph passes
  transformer
  IR(IR)
  end
  interpreter
  end
  prog--&gt;scalac
  scalac--&gt;exec
  exec--&gt;|meta -expansion|expanded
  expanded--&gt;|staging|OIR
  OIR--&gt;transformer
  IR--&gt;transformer
  transformer--&gt;IR
  IR--&gt;interpreter
</div>
<!-- htmlmin:ignore -->
</div>
</section><section id="scala-flow-integration" class="slide level2">
<h2>Scala-flow integration</h2>
<p>Having an interpreter enable to run spatial as a batch node !</p>
</section></section>
<section><section id="spatial-implementation-of-the-rbpf" class="titleslide slide level1"><h1>Spatial implementation of the RBPF</h1></section><section id="meta-programmation" class="slide level2">
<h2>Meta-programmation</h2>
<p>The RPBF algorithm is highly factorisable as matrix and vec operations.</p>
<p>Meta-programmation enable 0-cost abstractions</p>
<p>I wrote a Spatial matrix and vec library as a meta-programmable layer</p>
</section><section id="section-8" class="slide level2">
<h2></h2>
<p>Spatial is an embedded scala DSL</p>
<p>The DSL go through the Spatial compiler at runtime</p>
<p>The Spatial program in Scala is expanded into the DSL before going through the Spatial Compiler</p>
<p>It is during this step of ‚Äúmeta-expansion‚Äù that the matrix are expanded</p>
<p>also enable dimension check before compilation</p>
</section><section id="section-9" class="slide level2">
<h2></h2>
<p><code>scala.List.tabulate(10)(i =&gt; DSLNode(i))</code></p>
<pre><code>DSLNode(0)
DSLNode(1)
...</code></pre>
</section><section id="section-10" class="slide level2">
<h2></h2>
<pre><code>val a = DenseMatrix(x,y)(...)
val b = DenseMatrix(y,z)(...)
a*b</code></pre>
<pre><code>val a = RegFile(h,w)(...)
val b = RegFile(h,w)(...)
val c = RegFile(h,w)(...)

Foreach { Foreach { Foreach { ... } } }</code></pre>
</section><section id="views" class="slide level2">
<h2>Views</h2>
<p>Views are part of that matrix library.</p>
<p>They enable to transpose the matrix, identity matrix and other transformation by changing access as meta-programmation</p>
<p>Also enable to use optimal space and operations for diag or sparce matrices.</p>
</section><section id="pipelining" class="slide level2">
<h2>Pipelining</h2>
<p>To fit on chip, impossible to duplicate hardware for parrallelization</p>
<p>pipelining was used instead</p>
<p>pipelining require to adjust the code such read and write are as close as possible</p>
<p>else memory must be buffered and the area usage explode</p>
</section><section id="section-11" class="slide level2">
<h2></h2>
<p>Require to think factorisation in term of memory access instead of function (since all functions are expanded)</p>
</section></section>
<section><section id="conclusion" class="titleslide slide level1"><h1>Conclusion</h1></section><section id="section-12" class="slide level2">
<h2></h2>
<ul>
<li>Self-contained inter-disciplinary work</li>
<li>Improve state-of-the-art of POSE estimation</li>
<li>Enhance spatial ecosystem</li>
<li>Prove that Spatial can be applied to embedded systems</li>
</ul>
</section><section id="thank-you" class="slide level2">
<h2>Thank you!</h2>
<p>Questions ?</p>
</section></section>
	    </div>
	</div>

	<script src="reveal.js/lib/js/head.min.js"></script>
	<script src="reveal.js/js/reveal.js"></script>

	<script>

	 // Full list of configuration options available at:
	 // https://github.com/hakimel/reveal.js#configuration
	 Reveal.initialize({
	     	     	     	                  // Push each slide change to the browser history
             history: true,
	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     	     viewDistance: 40,
             // Optional reveal.js plugins
             dependencies: [
		 { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
		 { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
		 		 { src: 'reveal.js/plugin/notes/notes.js', async: true },
             ]
	 });

	</script>
		<script src="mermaid.min.js"></script>
<script> mermaid.initialize({ startOnLoad: true, cloneCssStyles: false, logLevel: 1 }); </script>
	    </body>
</html>
